# Regression-Tree-Guided Probabilistic Hull Generation

æœ¬é¡¹ç›®å®žçŽ°äº†åŸºäºŽå›žå½’æ ‘å¼•å¯¼çš„æ¦‚çŽ‡å¤–å£³ç”Ÿæˆæ–¹æ³•ï¼Œç”¨äºŽç¥žç»ç½‘ç»œæ¦‚çŽ‡éªŒè¯ã€‚

This project implements a regression-tree-guided probabilistic hull generation method for neural network probabilistic verification.

## ðŸ“‹ ç›®å½• / Table of Contents

- [é¡¹ç›®ç®€ä»‹ / Project Introduction](#é¡¹ç›®ç®€ä»‹--project-introduction)
- [çŽ¯å¢ƒé…ç½® / Environment Setup](#çŽ¯å¢ƒé…ç½®--environment-setup)
- [å¿«é€Ÿå¼€å§‹ / Quick Start](#å¿«é€Ÿå¼€å§‹--quick-start)
- [é¡¹ç›®ç»“æž„ / Project Structure](#é¡¹ç›®ç»“æž„--project-structure)
- [æ ¸å¿ƒç®—æ³• / Core Algorithms](#æ ¸å¿ƒç®—æ³•--core-algorithms)
- [å®žéªŒç»“æžœ / Experimental Results](#å®žéªŒç»“æžœ--experimental-results)

## ðŸŽ¯ é¡¹ç›®ç®€ä»‹ / Project Introduction

æœ¬é¡¹ç›®æå‡ºäº†ä¸€ç§å›žå½’æ ‘å¼•å¯¼çš„æ¦‚çŽ‡å¤–å£³ç”Ÿæˆæ–¹æ³•ï¼Œç”¨äºŽç¥žç»ç½‘ç»œçš„æ¦‚çŽ‡éªŒè¯ã€‚ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š

This project proposes a regression-tree-guided probabilistic hull generation method for neural network probabilistic verification. Key features include:

- **æ™ºèƒ½é‡‡æ ·ç­–ç•¥ / Intelligent Sampling Strategies**ï¼šè¾¹ç•Œæ„ŸçŸ¥é‡‡æ ·å’Œåˆ†å¸ƒå¼•å¯¼é‡‡æ ·
  - Boundary-aware sampling and distribution-guided sampling
- **å›žå½’æ ‘å¼•å¯¼åˆ†åŒº / Regression Tree-Guided Partitioning**ï¼šè‡ªé€‚åº”åŒºåŸŸåˆ’åˆ†ï¼ŒåŸºäºŽæ¦‚çŽ‡è´¨é‡å¼•å¯¼çš„åˆ†åŒºç­–ç•¥
  - Adaptive region partitioning with probability mass-guided partitioning strategies
- **æ¦‚çŽ‡éªŒè¯ / Probabilistic Verification**ï¼šåŸºäºŽ CROWN è¾¹ç•Œè®¡ç®—çš„å®‰å…¨æ¦‚çŽ‡ä¼°è®¡
  - Safety probability estimation based on CROWN bound computation

## ðŸ”§ çŽ¯å¢ƒé…ç½® / Environment Setup

### ç³»ç»Ÿè¦æ±‚ / System Requirements

- Python 3.8+ (auto_LiRPA è¦æ±‚ Python 3.7+ / auto_LiRPA requires Python 3.7+)
- PyTorch >=1.11.0, <2.3.0 (auto_LiRPA çš„ä¸¥æ ¼ç‰ˆæœ¬è¦æ±‚ / Strict version requirement from auto_LiRPA)
- CUDA 11.1+ (å¯é€‰ï¼Œç”¨äºŽ GPU åŠ é€Ÿ / Optional, for GPU acceleration)

### å®‰è£…æ–¹æ³• / Installation Methods

#### æ–¹æ³• 1: ä½¿ç”¨ Conda (æŽ¨è) / Method 1: Using Conda (Recommended)

```bash
# åˆ›å»º conda çŽ¯å¢ƒ / Create conda environment
conda env create -f environment.yml

# æ¿€æ´»çŽ¯å¢ƒ / Activate environment
conda activate prob-verification

# å®‰è£… auto_LiRPA (ä½œä¸ºå­æ¨¡å—) / Install auto_LiRPA (as submodule)
cd auto_LiRPA
pip install -e .

# å¯é€‰ï¼šæž„å»º CUDA æ¨¡å—ä»¥åŠ é€Ÿè®¡ç®— / Optional: Build CUDA modules for faster computation
python auto_LiRPA/cuda_utils.py install
```

#### æ–¹æ³• 2: ä½¿ç”¨ pip / Method 2: Using pip

```bash
# åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ / Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ– / Install dependencies
pip install -r requirements.txt

# å®‰è£… auto_LiRPA (ä½œä¸ºå­æ¨¡å—) / Install auto_LiRPA (as submodule)
cd auto_LiRPA
pip install -e .

# å¯é€‰ï¼šæž„å»º CUDA æ¨¡å— / Optional: Build CUDA modules
python auto_LiRPA/cuda_utils.py install
```

**é‡è¦æç¤º / Important Note**ï¼šauto_LiRPA éœ€è¦ä½œä¸ºå­æ¨¡å—åŒ…å«åœ¨é¡¹ç›®ä¸­ã€‚å¦‚æžœä½¿ç”¨ Git å…‹éš†ï¼Œè¯·è¿è¡Œï¼š

auto_LiRPA needs to be included as a submodule in the project. If cloning via Git, run:

```bash
git submodule update --init --recursive
```

## ðŸš€ å¿«é€Ÿå¼€å§‹ / Quick Start

### è¿è¡Œå®žéªŒ / Running Experiments

1. **ACAS Xu å®žéªŒ (ReLU ç½‘ç»œ) / ACAS Xu Experiments (ReLU Networks)**:
   ```bash
   cd src
   python acas.py
   ```

2. **ACAS Xu å®žéªŒ (Tanh ç½‘ç»œ) / ACAS Xu Experiments (Tanh Networks)**:
   ```bash
   cd src
   python acas_tanh.py
   ```

3. **RocketNet å®žéªŒ / RocketNet Experiments**:
   ```bash
   cd src
   python rocketnet.py
   ```

### å®žéªŒç»“æžœ / Experimental Results

æ‰€æœ‰å®žéªŒç»“æžœå°†ä¿å­˜åœ¨ `results/` ç›®å½•ä¸­ï¼š

All experimental results will be saved in the `results/` directory:

- `results/acas_experiments/` - ACAS å®žéªŒç»“æžœ / ACAS experiment results
- `results/tanh_experiments/` - Tanh ç½‘ç»œå®žéªŒç»“æžœ / Tanh network experiment results
- `results/rocketnet_experiments/` - RocketNet å®žéªŒç»“æžœ / RocketNet experiment results

## ðŸ“ é¡¹ç›®ç»“æž„ / Project Structure

```
â”œâ”€â”€ src/                          # æºä»£ç ç›®å½• / Source code directory
â”‚   â”œâ”€â”€ acas.py                  # ACAS Xu ReLU ç½‘ç»œå®žéªŒä¸»ç¨‹åº / ACAS Xu ReLU network experiment main program
â”‚   â”œâ”€â”€ acas_tanh.py             # ACAS Xu Tanh ç½‘ç»œå®žéªŒä¸»ç¨‹åº / ACAS Xu Tanh network experiment main program
â”‚   â”œâ”€â”€ rocketnet.py             # RocketNet å®žéªŒä¸»ç¨‹åº / RocketNet experiment main program
â”‚   â”œâ”€â”€ construct_acas_tanh.py   # ACAS Tanh ç½‘ç»œæž„å»ºå·¥å…· / ACAS Tanh network construction tool
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                   # å·¥å…·å‡½æ•° / Utility functions
â”‚   â”‚   â”œâ”€â”€ load.py              # æ¨¡åž‹åŠ è½½å‡½æ•° / Model loading functions
â”‚   â”‚   â”œâ”€â”€ utils.py             # æ ¸å¿ƒè®¡ç®—å·¥å…· / Core computational tools
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ samplers/                # é‡‡æ ·å™¨æ¨¡å— / Sampler modules
â”‚   â”‚   â”œâ”€â”€ uniform_boundary_sampler.py      # å‡åŒ€è¾¹ç•Œé‡‡æ · / Uniform boundary sampling
â”‚   â”‚   â”œâ”€â”€ distribution_boundary_sampler.py # åˆ†å¸ƒè¾¹ç•Œé‡‡æ · / Distribution boundary sampling
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ regression_tree/         # å›žå½’æ ‘æ¨¡å— / Regression tree modules
â”‚   â”‚   â”œâ”€â”€ tree_builder.py      # å†³ç­–æ ‘æž„å»ºå™¨ / Decision tree builder
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ models/                  # ç½‘ç»œæ¨¡åž‹ / Network models
â”‚       â”œâ”€â”€ tiny_network.py     # 2D ç¤ºä¾‹ç½‘ç»œ / 2D example network
â”‚       â”œâ”€â”€ deep_network_2d.py  # æ·±åº¦ 2D ç½‘ç»œ / Deep 2D network
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ checkpoints/                 # é¢„è®­ç»ƒæ¨¡åž‹ / Pre-trained models (see checkpoints/README.md)
â”‚   â”œâ”€â”€ acas/                   # ACAS ReLU æ¨¡åž‹ / ACAS ReLU models
â”‚   â”œâ”€â”€ acas_tanh/              # ACAS Tanh æ¨¡åž‹ / ACAS Tanh models
â”‚   â””â”€â”€ RocketNetReLU/          # RocketNet æ¨¡åž‹ / RocketNet models
â”‚
â”œâ”€â”€ docs/                        # æ–‡æ¡£ / Documentation
â”‚   â””â”€â”€ artifacts.md            # èµ„æºèŽ·å–è¯´æ˜Ž / Resource acquisition guide
â”‚
â”œâ”€â”€ requirements.txt             # Python ä¾èµ– / Python dependencies
â”œâ”€â”€ environment.yml              # Conda çŽ¯å¢ƒé…ç½® / Conda environment configuration
â””â”€â”€ README.md                    # æœ¬æ–‡ä»¶ / This file
```

## ðŸ”¬ æ ¸å¿ƒç®—æ³• / Core Algorithms

æœ¬é¡¹ç›®å®žçŽ°äº†ä»¥ä¸‹å…³é”®ç®—æ³•ï¼š

This project implements the following key algorithms:

1. **æ™ºèƒ½é‡‡æ ·ç­–ç•¥ / Intelligent Sampling Strategies**ï¼š
   - è¾¹ç•Œæ„ŸçŸ¥é‡‡æ · / Boundary-aware sampling
   - åˆ†å¸ƒå¼•å¯¼é‡‡æ · / Distribution-guided sampling
   - æ··åˆé‡‡æ ·ç­–ç•¥ / Mixed sampling strategies

2. **å›žå½’æ ‘å¼•å¯¼åˆ†åŒº / Regression Tree-Guided Partitioning**ï¼š
   - è‡ªé€‚åº”åŒºåŸŸåˆ’åˆ† / Adaptive region partitioning
   - æ¦‚çŽ‡è´¨é‡å¼•å¯¼çš„åˆ†åŒºç­–ç•¥ / Probability mass-guided partitioning strategies
   - å¹¶è¡ŒåŒ–æ ‘æž„å»º / Parallelized tree construction

3. **æ¦‚çŽ‡éªŒè¯ / Probabilistic Verification**ï¼š
   - CROWN è¾¹ç•Œè®¡ç®— / CROWN bound computation
   - å®‰å…¨æ¦‚çŽ‡ä¼°è®¡ / Safety probability estimation
   - æ”¶æ•›æ£€æŸ¥ / Convergence checking

## ðŸ“Š å®žéªŒç»“æžœ / Experimental Results

æ¯ä¸ªå®žéªŒè¾“å‡ºä»¥ä¸‹å…³é”®æŒ‡æ ‡ï¼š

Each experiment outputs the following key metrics:

- **Ls**: ä¸‹ç•Œå®‰å…¨æ¦‚çŽ‡ / Lower safe probability
- **Us**: ä¸Šç•Œå®‰å…¨æ¦‚çŽ‡ / Upper safe probability
- **Us-Ls**: æ¦‚çŽ‡åŒºé—´å®½åº¦ / Probability interval width
- **time**: è¿è¡Œæ—¶é—´ (ç§’) / Runtime (seconds)

è¾ƒå°çš„ `Us-Ls` å€¼è¡¨ç¤ºæ›´ç²¾ç¡®çš„æ¦‚çŽ‡ä¼°è®¡ã€‚

Smaller `Us-Ls` values indicate more precise probability estimates.

### å®žéªŒå‚æ•° / Experimental Parameters

å…³é”®å®žéªŒå‚æ•°ï¼ˆåœ¨è„šæœ¬ä¸­å›ºå®šï¼‰ï¼š

Key experimental parameters (fixed in scripts):

- **æ€»é‡‡æ ·æ•° / Total samples**: 1000 (ACAS), 9000 (RocketNet)
- **å¢žé‡é‡‡æ ·æ•° / Incremental samples**: 100 (ACAS), 900 (RocketNet)
- **æœ€å¤§æ ‘æ·±åº¦ / Maximum tree depth**: 5
- **æœªçŸ¥æ¦‚çŽ‡é˜ˆå€¼ / Unknown probability threshold**: 1e-5 (ACAS), 1e-3 (RocketNet)
- **ç³»æ•°å‚æ•° / Coefficient parameter**: 0.3

## ðŸ“„ è®¸å¯è¯ / License

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](LICENSE) è®¸å¯è¯ã€‚è¯¦æƒ…è¯·å‚é˜… LICENSE æ–‡ä»¶ã€‚

This project is licensed under the [MIT License](LICENSE). See the LICENSE file for details.

## ðŸ”— ç›¸å…³èµ„æº / Related Resources

- **æ¨¡åž‹æƒé‡ / Model Weights**: è¯·å‚é˜… [checkpoints/README.md](checkpoints/README.md) äº†è§£å¦‚ä½•èŽ·å–é¢„è®­ç»ƒæ¨¡åž‹ / See [checkpoints/README.md](checkpoints/README.md) for how to obtain pre-trained models
- **å®žéªŒèµ„æº / Experimental Resources**: è¯·å‚é˜… [docs/artifacts.md](docs/artifacts.md) äº†è§£é¢å¤–çš„å®žéªŒæ•°æ®å’Œèµ„æº / See [docs/artifacts.md](docs/artifacts.md) for additional experimental data and resources
